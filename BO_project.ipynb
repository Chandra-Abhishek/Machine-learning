{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "technological-supply",
   "metadata": {},
   "source": [
    "# Direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "celtic-richards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimum: x1=0.799, x2=0.898, x3=0.115, x4=0.967, y=5.281\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import GPy\n",
    "\n",
    "from Booster_single_obj_new import Booster\n",
    "\n",
    "pts = 20\n",
    "X = np.random.uniform(0, 1, (pts, 4))\n",
    "y = np.random.uniform(0, 0, (pts, 1))\n",
    "Cons = np.random.uniform(0, 0, (9, pts))\n",
    "for i in range(pts):\n",
    "    y[i],Cons[:,i]=Booster(X[i,:])\n",
    "    y[i] = -y[i]\n",
    "\n",
    "k = GPy.kern.RBF(4)\n",
    "m = GPy.models.GPRegression(X, y, k)\n",
    "m.optimize()\n",
    "xi = 0.01\n",
    "\n",
    "\n",
    "mean_cons = np.zeros((9))\n",
    "std_cons = np.zeros((9))\n",
    "for i in range(9):\n",
    "    mean_cons[i] = np.mean(Cons[:,i])\n",
    "    std_cons[i] = np.std(Cons[:, i])\n",
    "ratio = mean_cons/std_cons\n",
    "cdf = norm.cdf(ratio)\n",
    "term = np.prod(cdf)\n",
    "\n",
    "# perform the optimization process\n",
    "# select the next point to sample\n",
    "nbiter = 10\n",
    "for i in range(nbiter):\n",
    "    Xsamples = np.random.uniform(0, 1, (pts, 4))\n",
    "    yhat, _ = m.predict(X, full_cov=False)\n",
    "    best = np.max(yhat)\n",
    "    mu, std = m.predict(Xsamples, full_cov=False)\n",
    "    scores = ((mu - best)*norm.cdf((mu - best - xi) / (std))+std*norm.pdf((mu - best) / (std)))*term\n",
    "    ix = np.argmax(scores)\n",
    "    x = Xsamples[ix, :][:,None].T\n",
    "    x1 = x[0,0]\n",
    "    x2 = x[0,1]\n",
    "    x3 = x[0,2]\n",
    "    x4 = x[0,3]\n",
    "    \n",
    "    for i in range(1):\n",
    "        actual,Cons[:,i]=Booster(x[i,:])\n",
    "    X = np.concatenate((X, x), axis=0)\n",
    "    y = np.vstack((y, [[actual]]))\n",
    "    m = GPy.models.GPRegression(X, y, k)\n",
    "\n",
    "ix = np.argmax(y)\n",
    "print('optimum: x1=%.3f, x2=%.3f, x3=%.3f, x4=%.3f, y=%.3f' % (X[ix,0], X[ix,1], X[ix,2], X[ix,3], y[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-replication",
   "metadata": {},
   "source": [
    "# EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "agricultural-windows",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Result: x1=0.024, x2=0.136, x3=0.280, x4=0.883, y=5.186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pts = 20\n",
    "X = np.random.uniform(0, 1, (pts, 4))\n",
    "y = np.random.uniform(0, 0, (pts, 1))\n",
    "Cons = np.random.uniform(0, 0, (9, pts))\n",
    "for i in range(pts):\n",
    "    y[i],Cons[:,i]=Booster(X[i,:])\n",
    "    y[i] = -y[i]\n",
    "\n",
    "#y = np.array([objective(x1,x2) for (x1,x2) in zip(X[:,0], X[:,1])])[:,None]\n",
    "k = GPy.kern.RBF(4)\n",
    "m = GPy.models.GPRegression(X, y, k)\n",
    "m.optimize()\n",
    "xi = 0.01\n",
    "\n",
    "\n",
    "# perform the optimization process\n",
    "# select the next point to sample\n",
    "iter = 60\n",
    "for i in range(iter):\n",
    "    Xsamples = np.random.uniform(0, 1, (pts, 4))\n",
    "    # calculate the acquisition function for each sample\n",
    "\n",
    "    yhat, _ = m.predict(X, full_cov=False)\n",
    "    best = np.max(yhat)\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = m.predict(Xsamples, full_cov=False)\n",
    "    # calculate the probability of improvement\n",
    "    scores = (mu - best)*norm.cdf((mu - best - xi) / (std))+std*norm.pdf((mu - best) / (std))\n",
    "    # locate the index of the largest scores\n",
    "    ix = np.argmax(scores)\n",
    "    x = Xsamples[ix, :][:,None].T\n",
    "    # sample the point\n",
    "    x1 = x[0,0]\n",
    "    x2 = x[0,1]\n",
    "    x3 = x[0,2]\n",
    "    x4 = x[0,3]\n",
    "    \n",
    "    for i in range(1):\n",
    "        actual,Cons[:,i]=Booster(x[i,:])\n",
    "   \n",
    "        # summarize the finding\n",
    "    #est, _ = m.predict([[x]], full_cov=False)\n",
    "    #print(\"est: \",est)\n",
    "    #print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
    "        # add the data to the dataset\n",
    "    \n",
    "    X = np.concatenate((X, x), axis=0)\n",
    "    y = np.vstack((y, [[actual]]))\n",
    "        # update the model\n",
    "    m = GPy.models.GPRegression(X, y, k)\n",
    "\n",
    "# best result\n",
    "ix = np.argmax(y)\n",
    "print('Best Result: x1=%.3f, x2=%.3f, x3=%.3f, x4=%.3f, y=%.3f' % (X[ix,0], X[ix,1], X[ix,2], X[ix,3], y[ix]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-compensation",
   "metadata": {},
   "source": [
    "# UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "turned-column",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Result: x1=0.087, x2=0.604, x3=0.308, x4=0.835, y=4.923\n"
     ]
    }
   ],
   "source": [
    "pts = 20\n",
    "X = np.random.uniform(0, 1, (pts, 4))\n",
    "y = np.random.uniform(0, 0, (pts, 1))\n",
    "Cons = np.random.uniform(0, 0, (9, pts))\n",
    "for i in range(pts):\n",
    "    y[i],Cons[:,i]=Booster(X[i,:])\n",
    "    y[i] = -y[i]\n",
    "\n",
    "k = GPy.kern.RBF(4)\n",
    "m = GPy.models.GPRegression(X, y, k)\n",
    "m.optimize()\n",
    "xi = 0.01\n",
    "\n",
    "# perform the optimization process\n",
    "# select the next point to sample\n",
    "iters = 60\n",
    "\n",
    "for i in range(iter):\n",
    "    Xsamples = np.random.uniform(0, 1, (pts, 4))\n",
    "    # calculate the acquisition function for each sample\n",
    "\n",
    "    yhat, _ = m.predict(X, full_cov=False)\n",
    "    best = np.max(yhat)\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = m.predict(Xsamples, full_cov=False)\n",
    "    # calculate the probability of improvement\n",
    "    scores = mu + xi*std\n",
    "    # locate the index of the largest scores\n",
    "    ix = np.argmax(scores)\n",
    "    x = Xsamples[ix, :][:,None].T\n",
    "    # sample the point\n",
    "    x1 = x[0,0]\n",
    "    x2 = x[0,1]\n",
    "    x3 = x[0,2]\n",
    "    x4 = x[0,3]\n",
    "\n",
    "    for i in range(1):\n",
    "        actual,Cons[:,i]=Booster(x[i,:])\n",
    "\n",
    "        # summarize the finding\n",
    "    #est, _ = m.predict([[x]], full_cov=False)\n",
    "    #print(\"est: \",est)\n",
    "    #print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
    "        # add the data to the dataset\n",
    "\n",
    "    X = np.concatenate((X, x), axis=0)\n",
    "    y = np.vstack((y, [[actual]]))\n",
    "        # update the model\n",
    "    m = GPy.models.GPRegression(X, y, k)\n",
    "\n",
    "# best result\n",
    "ix = np.argmax(y)\n",
    "print('Best Result: x1=%.3f, x2=%.3f, x3=%.3f, x4=%.3f, y=%.3f' % (X[ix,0], X[ix,1], X[ix,2], X[ix,3], y[ix]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-pacific",
   "metadata": {},
   "source": [
    "# POF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "photographic-pioneer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Result: x1=0.237, x2=0.294, x3=0.196, x4=0.731, y=5.073\n"
     ]
    }
   ],
   "source": [
    "pts = 20\n",
    "X = np.random.uniform(0, 1, (pts, 4))\n",
    "y = np.random.uniform(0, 0, (pts, 1))\n",
    "Cons = np.random.uniform(0, 0, (9, pts))\n",
    "for i in range(pts):\n",
    "    y[i],Cons[:,i]=Booster(X[i,:])\n",
    "    y[i] = -y[i]\n",
    "\n",
    "\n",
    "#y = np.array([objective(x1,x2) for (x1,x2) in zip(X[:,0], X[:,1])])[:,None]\n",
    "k = GPy.kern.RBF(4)\n",
    "m = GPy.models.GPRegression(X, y, k)\n",
    "m.optimize()\n",
    "xi = 0.01\n",
    "\n",
    "mean_cons = np.zeros((9))\n",
    "std_cons = np.zeros((9))\n",
    "for i in range(9):\n",
    "    mean_cons[i] = np.mean(Cons[:,i])\n",
    "    std_cons[i] = np.std(Cons[:, i])\n",
    "ratio = mean_cons/std_cons\n",
    "cdf = norm.cdf(ratio)\n",
    "term = np.prod(cdf)\n",
    "\n",
    "# perform the optimization process\n",
    "# select the next point to sample\n",
    "iter = 60\n",
    "for i in range(iter):\n",
    "    Xsamples = np.random.uniform(0, 1, (pts, 4))\n",
    "    # calculate the acquisition function for each sample\n",
    "\n",
    "    yhat, _ = m.predict(X, full_cov=False)\n",
    "    best = np.max(yhat)\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = m.predict(Xsamples, full_cov=False)\n",
    "    # calculate the probability of improvement\n",
    "    scores = (mu - best)*norm.cdf((mu - best - xi) / (std))+std*norm.pdf((mu - best) / (std)) * term\n",
    "    # locate the index of the largest scores\n",
    "    ix = np.argmax(scores)\n",
    "    x = Xsamples[ix, :][:,None].T\n",
    "    # sample the point\n",
    "    x1 = x[0,0]\n",
    "    x2 = x[0,1]\n",
    "    x3 = x[0,2]\n",
    "    x4 = x[0,3]\n",
    "    \n",
    "    for i in range(1):\n",
    "        actual,Cons[:,i]=Booster(x[i,:])\n",
    "   \n",
    "        # summarize the finding\n",
    "    #est, _ = m.predict([[x]], full_cov=False)\n",
    "    #print(\"est: \",est)\n",
    "    #print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
    "        # add the data to the dataset\n",
    "    \n",
    "    X = np.concatenate((X, x), axis=0)\n",
    "    y = np.vstack((y, [[actual]]))\n",
    "        # update the model\n",
    "    m = GPy.models.GPRegression(X, y, k)\n",
    "\n",
    "# best result\n",
    "ix = np.argmax(y)\n",
    "print('Best Result: x1=%.3f, x2=%.3f, x3=%.3f, x4=%.3f, y=%.3f' % (X[ix,0], X[ix,1], X[ix,2], X[ix,3], y[ix]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-heaven",
   "metadata": {},
   "source": [
    "# PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "expensive-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Result: x1=0.391, x2=0.472, x3=0.258, x4=0.828, y=5.007\n"
     ]
    }
   ],
   "source": [
    "pts = 20\n",
    "X = np.random.uniform(0, 1, (pts, 4))\n",
    "y = np.random.uniform(0, 0, (pts, 1))\n",
    "Cons = np.random.uniform(0, 0, (9, pts))\n",
    "for i in range(pts):\n",
    "    y[i],Cons[:,i]=Booster(X[i,:])\n",
    "    y[i] = -y[i]\n",
    "\n",
    "\n",
    "#y = np.array([objective(x1,x2) for (x1,x2) in zip(X[:,0], X[:,1])])[:,None]\n",
    "k = GPy.kern.RBF(4)\n",
    "m = GPy.models.GPRegression(X, y, k)\n",
    "m.optimize()\n",
    "xi = 0.01\n",
    "\n",
    "\n",
    "# perform the optimization process\n",
    "# select the next point to sample\n",
    "iter = 60\n",
    "for i in range(iter):\n",
    "    Xsamples = np.random.uniform(0, 1, (pts, 4))\n",
    "    # calculate the acquisition function for each sample\n",
    "\n",
    "    yhat, _ = m.predict(X, full_cov=False)\n",
    "    best = np.max(yhat)\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = m.predict(Xsamples, full_cov=False)\n",
    "    # calculate the probability of improvement\n",
    "    scores = norm.cdf((mu - best - xi) / (std+1E-9))\n",
    "    # locate the index of the largest scores\n",
    "    ix = np.argmax(scores)\n",
    "    x = Xsamples[ix, :][:,None].T\n",
    "    # sample the point\n",
    "    x1 = x[0,0]\n",
    "    x2 = x[0,1]\n",
    "    x3 = x[0,2]\n",
    "    x4 = x[0,3]\n",
    "    \n",
    "    for i in range(1):\n",
    "        actual,Cons[:,i]=Booster(x[i,:])\n",
    "   \n",
    "        # summarize the finding\n",
    "    #est, _ = m.predict([[x]], full_cov=False)\n",
    "    #print(\"est: \",est)\n",
    "    #print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
    "        # add the data to the dataset\n",
    "    \n",
    "    X = np.concatenate((X, x), axis=0)\n",
    "    y = np.vstack((y, [[actual]]))\n",
    "        # update the model\n",
    "    m = GPy.models.GPRegression(X, y, k)\n",
    "\n",
    "# best result\n",
    "ix = np.argmax(y)\n",
    "print('Best Result: x1=%.3f, x2=%.3f, x3=%.3f, x4=%.3f, y=%.3f' % (X[ix,0], X[ix,1], X[ix,2], X[ix,3], y[ix]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-country",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-windsor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-recommendation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
